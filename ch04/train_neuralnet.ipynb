{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1720081926684
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\USER\\Desktop\\neural_network_basic\\ch04\n",
            "c:\\Users\\USER\\Desktop\\neural_network_basic\n",
            "0.13401666666666667 0.134\n",
            "0.9042166666666667 0.9086\n",
            "0.92285 0.926\n",
            "0.9357333333333333 0.9356\n",
            "0.94385 0.9446\n",
            "0.9523166666666667 0.9501\n",
            "0.95545 0.952\n",
            "0.9604333333333334 0.9578\n",
            "0.9635 0.9608\n",
            "0.9655166666666667 0.9616\n",
            "0.9690666666666666 0.9639\n",
            "0.97035 0.9646\n",
            "0.9722 0.9662\n",
            "0.9747833333333333 0.9676\n",
            "0.9755833333333334 0.9682\n",
            "0.977 0.968\n",
            "0.97745 0.9678\n"
          ]
        }
      ],
      "source": [
        "# coding: utf-8\n",
        "import os, sys\n",
        "print(os.getcwd())\n",
        "current_dir = os.path.dirname(os.getcwd())\n",
        "print(current_dir)\n",
        "os.chdir(current_dir)\n",
        "\n",
        "#import torch\n",
        "import numpy as np\n",
        "from dataset.mnist import load_mnist\n",
        "from ch04.two_layer_net import TwoLayerNet\n",
        "\n",
        "#데이터 읽기\n",
        "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
        "\n",
        "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "#하이퍼파라미터\n",
        "iters_num = 10000 #반복횟수를 적절히 설정한다\n",
        "train_size = x_train.shape[0]\n",
        "batch_size = 100 #미니배치 크기\n",
        "learning_rate = 0.1\n",
        "\n",
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "# 1에폭당 반복 수\n",
        "iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "for i in range(iters_num):\n",
        "    #미니배치 획득\n",
        "    batch_mask = np.random.choice(train_size, batch_size)\n",
        "    x_batch = x_train[batch_mask]\n",
        "    t_batch = t_train[batch_mask]\n",
        "\n",
        "    #기울기 계산 \n",
        "    #grad = network.numerical_gradient(x_batch, t_batch) #수치 미분 방식\n",
        "    grad = network.gradient(x_batch, t_batch) # 오차역전파법 방식(훨씬 빠름)\n",
        "\n",
        "    #매개변수 갱신\n",
        "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
        "        network.params[key] -= learning_rate*grad[key]\n",
        "\n",
        "    #학습 경과 기록\n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    train_loss_list.append(loss)\n",
        "\n",
        "    #1에폭당 정확도 계산\n",
        "    if i % iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train, t_train)\n",
        "        test_acc = network.accuracy(x_test, t_test)\n",
        "        train_acc_list.append(train_acc)\n",
        "        test_acc_list.append(test_acc)\n",
        "        print(train_acc, test_acc)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
