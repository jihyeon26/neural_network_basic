{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d2bbd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59202706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.layers import Layer\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765978dc",
   "metadata": {},
   "source": [
    "## Step 1: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa85d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample parallel sentences (English -> Spanish)\n",
    "input_texts = [\n",
    "    \"Hello.\", \"How are you?\", \"I am learning machine translation.\", \"What is your name?\", \"I love programming.\"\n",
    "]\n",
    "target_texts = [\n",
    "    \"Hola.\", \"¿Cómo estás?\", \"Estoy aprendiendo traducción automática.\", \"¿Cuál es tu nombre?\", \"Me encanta programar.\"\n",
    "]\n",
    "\n",
    "target_texts = [\"startseq \" + x + \" endseq\" for x in target_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2afe92d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "input_tokenizer = Tokenizer()\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n",
    "\n",
    "output_tokenizer = Tokenizer()\n",
    "output_tokenizer.fit_on_texts(target_texts)\n",
    "output_sequences = output_tokenizer.texts_to_sequences(target_texts)\n",
    "\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "output_vocab_size = len(output_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf8a2ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "max_input_length = max([len(seq) for seq in input_sequences])\n",
    "max_output_length = max([len(seq) for seq in output_sequences])\n",
    "\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_input_length, padding='post')\n",
    "output_sequences = pad_sequences(output_sequences, maxlen=max_output_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81545dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the target data for training\n",
    "decoder_input_data = output_sequences[:, :-1]\n",
    "decoder_output_data = output_sequences[:, 1:]\n",
    "\n",
    "# Convert to one-hot\n",
    "decoder_output_data = np.array([np.eye(output_vocab_size)[seq] for seq in decoder_output_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf638f",
   "metadata": {},
   "source": [
    "## Step 2: Self-Attention Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba195ec5",
   "metadata": {},
   "source": [
    "Self-attention is a mechanism that allows a model to **focus on relevant parts of the input sequence** while processing each word. This is particularly useful in:\n",
    "1) Machine Translation (e.g., aligning words correctly)\n",
    "2) Text Summarization\n",
    "3) Speech Recognition\n",
    "4) Image Processing (Vision Transformers)\n",
    "In this implementation, self-attention is used for text based sequence-to-sequence modeling.\n",
    "\n",
    "\n",
    "Self-Attention works for a given an input sequence by computing a weighted representation of all words for each position. It does so using three key components:\n",
    "\n",
    "1. Query **(Q)**, Key **(K)**, and Value **(V)** Matrices\n",
    "For each word (token) in a sequence:\n",
    "\n",
    "Query (Q): What this word is looking for.\n",
    "Key (K): What this word represents.\n",
    "Value (V): The actual information in the word.\n",
    "\n",
    "2. Compute **Attention Scores**\n",
    "Next, we **calculate the similarity between each query and key** using dot-product attention:\n",
    "Each word in a sequence attends to every other word based on these scores.\n",
    "\n",
    "3. Apply **Scaling & Softmax**\n",
    "Since dot-product values can be large, we scale them. \n",
    "Next, Applying softmax converts scores into attention weights:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec91695",
   "metadata": {},
   "source": [
    "### Self-Attention class\n",
    "In this implementation of self-attention layer:\n",
    "1. We first initialize the weights in the **build** method, where:\n",
    "    1. **self.Wq**, **self.Wk**, **self.Wv** are the trainable weight matrices.\n",
    "    2. Their **shape is (feature_dim, feature_dim)**, meaning they transform input features into Q, K, and V representations.\n",
    "2. Applying Attention using **call** method. The **call()** method:\n",
    "   1. Computes **Q, K, V** by multiplying inputs (encoder/decoder output) with their respective weight matrices.\n",
    "   2. Computes **dot-product attention scores** using K.batch_dot(q, k, axes=[2, 2]), resulting in a (batch_size, seq_len, seq_len) matrix.\n",
    "   3. **Scales** the scores to avoid large values.\n",
    "   4. Applies **softmax** to normalize the attention scores.\n",
    "   5. **Multiplies attention weights with V** to get the final output.\n",
    "3. The **compute_output_shape** method defines the shape of the output tensor after the layer processes an input.\n",
    "    1. The output shape of the Self-Attention layer **remains the same** as the input shape.\n",
    "    2. The attention mechanism **transforms** the input but does not change its dimensions.4\n",
    "    3. If the attention layer changed the shape, you would modify compute_output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d54e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Self-Attention Layer\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d0f662",
   "metadata": {},
   "source": [
    "## Step 3: Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ab81002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,608</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,369</span> │ self_attention_1… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,096\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,352\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │    \u001b[38;5;34m196,608\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mSelfAttention\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m17\u001b[0m)     │      \u001b[38;5;34m4,369\u001b[0m │ self_attention_1… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,260,049</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,260,049\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,260,049</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,260,049\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Attention Mechanism\n",
    "attention_layer = SelfAttention()(encoder_outputs)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,))\n",
    "decoder_embedding = Embedding(output_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_attention = SelfAttention()(decoder_outputs)  # Apply attention\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_attention)\n",
    "\n",
    "# Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0119b4",
   "metadata": {},
   "source": [
    "## Step 4: Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfb5db0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.0000e+00 - loss: 2.8299\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.2800 - loss: 2.7916\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.2800 - loss: 2.7452\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.2800 - loss: 2.6809\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.2800 - loss: 2.5887\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.2400 - loss: 2.4642\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.2400 - loss: 2.3391\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.2400 - loss: 2.3483\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.2800 - loss: 2.3468\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.3200 - loss: 2.2750\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.3200 - loss: 2.2231\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.3200 - loss: 2.1928\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.3200 - loss: 2.1664\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.3200 - loss: 2.1304\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.3200 - loss: 2.0806\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.3200 - loss: 2.0234\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.3200 - loss: 1.9728\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.3200 - loss: 1.9371\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.3200 - loss: 1.9023\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.3200 - loss: 1.8525\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.3200 - loss: 1.7975\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3200 - loss: 1.7568\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3200 - loss: 1.7302\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3200 - loss: 1.6899\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.3200 - loss: 1.6308\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.3200 - loss: 1.5916\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.3200 - loss: 1.5783\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.3200 - loss: 1.5443\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.3200 - loss: 1.5174\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.2800 - loss: 1.5217\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.3200 - loss: 1.4937\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.3200 - loss: 1.4788\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.3200 - loss: 1.4585\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.3200 - loss: 1.4570\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.3200 - loss: 1.4508\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.3200 - loss: 1.4456\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.3600 - loss: 1.4256\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.3200 - loss: 1.4103\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.3200 - loss: 1.4222\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.3600 - loss: 1.4013\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.3600 - loss: 1.3922\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.3600 - loss: 1.3749\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.3600 - loss: 1.3568\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.3600 - loss: 1.3412\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.4000 - loss: 1.3201\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.3200 - loss: 1.2889\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.4000 - loss: 1.2512\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.4400 - loss: 1.2107\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.4400 - loss: 1.1648\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.5200 - loss: 1.1244\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.5600 - loss: 1.0804\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.6400 - loss: 1.0325\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6000 - loss: 0.9952\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5600 - loss: 0.9792\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6400 - loss: 0.9816\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6000 - loss: 0.9304\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6000 - loss: 0.9180\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5200 - loss: 0.9651\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.6000 - loss: 0.8920\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5200 - loss: 1.0788\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.6800 - loss: 0.8958\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.5600 - loss: 0.8826\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.5200 - loss: 0.8798\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.5600 - loss: 0.9249\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.6400 - loss: 0.8042\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5600 - loss: 0.8143\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.5600 - loss: 0.8327\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.6000 - loss: 0.7837\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.6400 - loss: 0.7522\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.6800 - loss: 0.7154\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7200 - loss: 0.7174\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6800 - loss: 0.7118\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7600 - loss: 0.6809\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8800 - loss: 0.6608\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.8000 - loss: 0.6534\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7600 - loss: 0.6394\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.7600 - loss: 0.6226\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7600 - loss: 0.6218\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.8000 - loss: 0.6156\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.8400 - loss: 0.6021\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.8000 - loss: 0.5961\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.8000 - loss: 0.5876\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.8000 - loss: 0.5721\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8000 - loss: 0.5654\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8400 - loss: 0.5592\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.8400 - loss: 0.5493\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.8400 - loss: 0.5367\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8400 - loss: 0.5257\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.8400 - loss: 0.5136\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8400 - loss: 0.5028\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.8400 - loss: 0.4926\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.8400 - loss: 0.4815\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.8400 - loss: 0.4707\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.8800 - loss: 0.4604\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.8800 - loss: 0.4500\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.8800 - loss: 0.4386\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.8400 - loss: 0.4284\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8400 - loss: 0.4173\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8800 - loss: 0.4059\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8400 - loss: 0.3955\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Train the Model\n",
    "history_glorot_adam = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbc9d4a",
   "metadata": {},
   "source": [
    "## Step 5: Plotting the training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0976ca82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting training loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0de28e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
