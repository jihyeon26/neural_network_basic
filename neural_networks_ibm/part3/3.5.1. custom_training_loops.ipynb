{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8077c844",
   "metadata": {},
   "source": [
    "## Custom Training Loops in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "204fbf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "# Suppress all Python warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set TensorFlow log level to suppress warnings and info messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Step 1: Set Up the Environment\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() \n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35a8b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the Model\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a5d3e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define Loss Function and Optimizer\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) \n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5b3af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 1\n",
      "Epoch 1 Step 0: Loss = 2.3743958473205566\n",
      "Epoch 1 Step 200: Loss = 0.39980998635292053\n",
      "Epoch 1 Step 400: Loss = 0.1824227124452591\n",
      "Epoch 1 Step 600: Loss = 0.190804585814476\n",
      "Epoch 1 Step 800: Loss = 0.21089746057987213\n",
      "Epoch 1 Step 1000: Loss = 0.48431193828582764\n",
      "Epoch 1 Step 1200: Loss = 0.1345197856426239\n",
      "Epoch 1 Step 1400: Loss = 0.26571205258369446\n",
      "Epoch 1 Step 1600: Loss = 0.23788246512413025\n",
      "Epoch 1 Step 1800: Loss = 0.15216906368732452\n",
      "Start of epoch 2\n",
      "Epoch 2 Step 0: Loss = 0.0945412814617157\n",
      "Epoch 2 Step 200: Loss = 0.1728932112455368\n",
      "Epoch 2 Step 400: Loss = 0.11890389025211334\n",
      "Epoch 2 Step 600: Loss = 0.08480465412139893\n",
      "Epoch 2 Step 800: Loss = 0.10181252658367157\n",
      "Epoch 2 Step 1000: Loss = 0.28182512521743774\n",
      "Epoch 2 Step 1200: Loss = 0.05708758533000946\n",
      "Epoch 2 Step 1400: Loss = 0.16776081919670105\n",
      "Epoch 2 Step 1600: Loss = 0.1877271980047226\n",
      "Epoch 2 Step 1800: Loss = 0.08635355532169342\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Implement the Custom Training Loop\n",
    "\n",
    "epochs = 2\n",
    "# train_dataset = train_dataset.repeat(epochs)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\n",
    "for epoch in range(epochs):\n",
    "    print(f'Start of epoch {epoch + 1}')\n",
    "\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch_train, training=True)  # Forward pass\n",
    "            loss_value = loss_fn(y_batch_train, logits)  # Compute loss\n",
    "\n",
    "        # Compute gradients and update weights\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        # Logging the loss every 200 steps\n",
    "        if step % 200 == 0:\n",
    "            print(f'Epoch {epoch + 1} Step {step}: Loss = {loss_value.numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5a66e7",
   "metadata": {},
   "source": [
    "### Adding Accuracy Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1ee75ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Flatten \n",
    "\n",
    "# Step 1: Set Up the Environment\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values to be between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 \n",
    "\n",
    "# Create a batched dataset for training\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72c5c43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the Model\n",
    "\n",
    "model = Sequential([ \n",
    "    Flatten(input_shape=(28, 28)),  # Flatten the input to a 1D vector\n",
    "    Dense(128, activation='relu'),  # First hidden layer with 128 neurons and ReLU activation\n",
    "    Dense(10)  # Output layer with 10 neurons for the 10 classes (digits 0-9)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67b6a2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define Loss Function, Optimizer, and Metric\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)  # Loss function for multi-class classification\n",
    "optimizer = tf.keras.optimizers.Adam()  # Adam optimizer for efficient training\n",
    "accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy()  # Metric to track accuracy during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd99587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 1\n",
      "Epoch 1 Step 0: Loss = 2.3632686138153076 Accuracy = 0.1875\n",
      "Epoch 1 Step 200: Loss = 0.4184502363204956 Accuracy = 0.8347325921058655\n",
      "Epoch 1 Step 400: Loss = 0.1777428388595581 Accuracy = 0.8687655925750732\n",
      "Epoch 1 Step 600: Loss = 0.1555330902338028 Accuracy = 0.8844113945960999\n",
      "Epoch 1 Step 800: Loss = 0.20300383865833282 Accuracy = 0.8966526389122009\n",
      "Epoch 1 Step 1000: Loss = 0.3931822180747986 Accuracy = 0.9040022492408752\n",
      "Epoch 1 Step 1200: Loss = 0.15781570971012115 Accuracy = 0.9107774496078491\n",
      "Epoch 1 Step 1400: Loss = 0.1900905966758728 Accuracy = 0.915662944316864\n",
      "Epoch 1 Step 1600: Loss = 0.21526694297790527 Accuracy = 0.9188007712364197\n",
      "Epoch 1 Step 1800: Loss = 0.14350934326648712 Accuracy = 0.922751247882843\n",
      "Start of epoch 2\n",
      "Epoch 2 Step 0: Loss = 0.08563232421875 Accuracy = 1.0\n",
      "Epoch 2 Step 200: Loss = 0.17792275547981262 Accuracy = 0.961442768573761\n",
      "Epoch 2 Step 400: Loss = 0.10861668735742569 Accuracy = 0.9585411548614502\n",
      "Epoch 2 Step 600: Loss = 0.04933779686689377 Accuracy = 0.9606904983520508\n",
      "Epoch 2 Step 800: Loss = 0.10719242691993713 Accuracy = 0.961532473564148\n",
      "Epoch 2 Step 1000: Loss = 0.25937527418136597 Accuracy = 0.9621316194534302\n",
      "Epoch 2 Step 1200: Loss = 0.09621845185756683 Accuracy = 0.9629475474357605\n",
      "Epoch 2 Step 1400: Loss = 0.09366306662559509 Accuracy = 0.9639766216278076\n",
      "Epoch 2 Step 1600: Loss = 0.19460386037826538 Accuracy = 0.9635774493217468\n",
      "Epoch 2 Step 1800: Loss = 0.0637468621134758 Accuracy = 0.9643427133560181\n",
      "Start of epoch 3\n",
      "Epoch 3 Step 0: Loss = 0.04016488790512085 Accuracy = 1.0\n",
      "Epoch 3 Step 200: Loss = 0.12546822428703308 Accuracy = 0.9752798676490784\n",
      "Epoch 3 Step 400: Loss = 0.08923524618148804 Accuracy = 0.9737375378608704\n",
      "Epoch 3 Step 600: Loss = 0.04412694275379181 Accuracy = 0.9747816324234009\n",
      "Epoch 3 Step 800: Loss = 0.061800483614206314 Accuracy = 0.9749922156333923\n",
      "Epoch 3 Step 1000: Loss = 0.14530712366104126 Accuracy = 0.9752435088157654\n",
      "Epoch 3 Step 1200: Loss = 0.07222045958042145 Accuracy = 0.975255012512207\n",
      "Epoch 3 Step 1400: Loss = 0.057137809693813324 Accuracy = 0.9755531549453735\n",
      "Epoch 3 Step 1600: Loss = 0.1421133428812027 Accuracy = 0.9752693772315979\n",
      "Epoch 3 Step 1800: Loss = 0.028675859794020653 Accuracy = 0.9756906032562256\n",
      "Start of epoch 4\n",
      "Epoch 4 Step 0: Loss = 0.024741558358073235 Accuracy = 1.0\n",
      "Epoch 4 Step 200: Loss = 0.07127364724874496 Accuracy = 0.981965184211731\n",
      "Epoch 4 Step 400: Loss = 0.07152751088142395 Accuracy = 0.9805174469947815\n",
      "Epoch 4 Step 600: Loss = 0.04749159887433052 Accuracy = 0.9811252355575562\n",
      "Epoch 4 Step 800: Loss = 0.0463484451174736 Accuracy = 0.9811953902244568\n",
      "Epoch 4 Step 1000: Loss = 0.09297940880060196 Accuracy = 0.9814248085021973\n",
      "Epoch 4 Step 1200: Loss = 0.055117908865213394 Accuracy = 0.9814477562904358\n",
      "Epoch 4 Step 1400: Loss = 0.03513317182660103 Accuracy = 0.9817317724227905\n",
      "Epoch 4 Step 1600: Loss = 0.08929521590471268 Accuracy = 0.9816520810127258\n",
      "Epoch 4 Step 1800: Loss = 0.019274599850177765 Accuracy = 0.9820065498352051\n",
      "Start of epoch 5\n",
      "Epoch 5 Step 0: Loss = 0.016051216050982475 Accuracy = 1.0\n",
      "Epoch 5 Step 200: Loss = 0.03791474550962448 Accuracy = 0.9866293668746948\n",
      "Epoch 5 Step 400: Loss = 0.06903189420700073 Accuracy = 0.9857387542724609\n",
      "Epoch 5 Step 600: Loss = 0.029663048684597015 Accuracy = 0.9863768815994263\n",
      "Epoch 5 Step 800: Loss = 0.022826289758086205 Accuracy = 0.9862671494483948\n",
      "Epoch 5 Step 1000: Loss = 0.05679934471845627 Accuracy = 0.9865759015083313\n",
      "Epoch 5 Step 1200: Loss = 0.041228484362363815 Accuracy = 0.9867298007011414\n",
      "Epoch 5 Step 1400: Loss = 0.031433720141649246 Accuracy = 0.986884355545044\n",
      "Epoch 5 Step 1600: Loss = 0.06980261206626892 Accuracy = 0.9867660999298096\n",
      "Epoch 5 Step 1800: Loss = 0.016450773924589157 Accuracy = 0.987003743648529\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Implement the Custom Training Loop with Accuracy\n",
    "\n",
    "epochs = 5  # Number of epochs for training\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Start of epoch {epoch + 1}')\n",
    "    \n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass: Compute predictions\n",
    "            logits = model(x_batch_train, training=True)\n",
    "            # Compute loss\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "        \n",
    "        # Compute gradients\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        # Apply gradients to update model weights\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        \n",
    "        # Update the accuracy metric\n",
    "        accuracy_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "        # Log the loss and accuracy every 200 steps\n",
    "        if step % 200 == 0:\n",
    "            print(f'Epoch {epoch + 1} Step {step}: Loss = {loss_value.numpy()} Accuracy = {accuracy_metric.result().numpy()}')\n",
    "    \n",
    "    # Reset the metric at the end of each epoch\n",
    "    accuracy_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cbc181",
   "metadata": {},
   "source": [
    "### Custom Callback for Advanced Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fa7199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Flatten \n",
    "\n",
    "# Step 1: Set Up the Environment\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values to be between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 \n",
    "\n",
    "# Create a batched dataset for training\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cecd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
