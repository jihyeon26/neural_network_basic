{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74645e09",
   "metadata": {},
   "source": [
    "## Building Advanced Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954fee6e",
   "metadata": {},
   "source": [
    "- Implement advanced Transformer models using Keras. \n",
    "\n",
    "- Apply Transformers to real-world sequential data tasks. \n",
    "\n",
    "- Build, train, and evaluate Transformer models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0cc01d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "479a5af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic stock_prices.csv created and loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a synthetic stock price dataset\n",
    "np.random.seed(42)\n",
    "data_length = 2000  # Adjust data length as needed\n",
    "trend = np.linspace(100, 200, data_length)\n",
    "noise = np.random.normal(0, 2, data_length)\n",
    "synthetic_data = trend + noise\n",
    "\n",
    "# Create a DataFrame and save as 'stock_prices.csv'\n",
    "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
    "data.to_csv('stock_prices.csv', index=False)\n",
    "print(\"Synthetic stock_prices.csv created and loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defe1e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1899, 100, 1)\n",
      "Shape of Y: (1899,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset \n",
    "data = pd.read_csv('stock_prices.csv') \n",
    "data = data[['Close']].values \n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Prepare the data for training\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 100\n",
    "X, Y = create_dataset(data, time_step)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", X.shape) \n",
    "print(\"Shape of Y:\", Y.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbc13d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    "\n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b40443df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a3799b",
   "metadata": {},
   "source": [
    "      Input\n",
    "        │\n",
    "        ▼\n",
    "  ┌────────────────────┐\n",
    "  │ Multi-Head Attention│\n",
    "  └────────────────────┘\n",
    "        │\n",
    "     Dropout\n",
    "        ▼\n",
    "Residual Add + LayerNorm\n",
    "        ▼\n",
    "  ┌────────────────────┐\n",
    "  │ Feed Forward Network│\n",
    "  └────────────────────┘\n",
    "        │\n",
    "     Dropout\n",
    "        ▼\n",
    "Residual Add + LayerNorm\n",
    "        ▼\n",
    "     Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "224cac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(EncoderLayer, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0c5e11",
   "metadata": {},
   "source": [
    "### Implement Transformer encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98b2c5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout \n",
    "\n",
    "class MultiHeadSelfAttention(Layer): \n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    " \n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    "class TransformerBlock(Layer): \n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n",
    "class TransformerEncoder(Layer): \n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerEncoder, self).__init__() \n",
    "        self.num_layers = num_layers \n",
    "        self.embed_dim = embed_dim \n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training=False): \n",
    "        x = inputs \n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x \n",
    "\n",
    "# Example usage \n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "inputs = tf.random.uniform((1, 100, embed_dim)) \n",
    "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training' \n",
    "print(outputs.shape)  # Should print (1, 100, 128) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f298c61",
   "metadata": {},
   "source": [
    "### Build and Compile the Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a1f3284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\wldhg\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the necessary parameters \n",
    "\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "outputs = tf.keras.layers.Dense(1)(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e898013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 117ms/step - loss: 11.6558\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 131ms/step - loss: 0.2082\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 146ms/step - loss: 0.2082\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 143ms/step - loss: 0.1332\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 144ms/step - loss: 0.1267\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 142ms/step - loss: 0.1280\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 143ms/step - loss: 0.1457\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 145ms/step - loss: 0.1545\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 145ms/step - loss: 0.1593\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 148ms/step - loss: 0.0956\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 153ms/step - loss: 0.1496\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - loss: 0.1252\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 151ms/step - loss: 0.0898\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 148ms/step - loss: 0.0783\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 151ms/step - loss: 0.0743\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 151ms/step - loss: 0.0685\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 152ms/step - loss: 0.1085\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 164ms/step - loss: 0.0551\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 166ms/step - loss: 0.0579\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 153ms/step - loss: 0.0820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x160c640a570>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa511b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions \n",
    "predictions = model.predict(X) \n",
    "predictions = scaler.inverse_transform(predictions) \n",
    " \n",
    "\n",
    "# Plot the predictions \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(data, label='True Data') \n",
    "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions') \n",
    "plt.xlabel('Time') \n",
    "plt.ylabel('Stock Price') \n",
    "plt.legend() \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce2654d",
   "metadata": {},
   "source": [
    "#### Add dropout to the Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e2103db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 117ms/step - loss: 8.6165\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 162ms/step - loss: 1.4008\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 151ms/step - loss: 0.9497\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 161ms/step - loss: 0.5888\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 156ms/step - loss: 0.2342\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 144ms/step - loss: 0.0862\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 147ms/step - loss: 0.0538\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 145ms/step - loss: 0.0288\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 146ms/step - loss: 0.0294\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - loss: 0.0308\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 150ms/step - loss: 0.0217\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 154ms/step - loss: 0.0200\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 160ms/step - loss: 0.0164\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 169ms/step - loss: 0.0166\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 197ms/step - loss: 0.0157\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 151ms/step - loss: 0.0146\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 155ms/step - loss: 0.0142\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 162ms/step - loss: 0.0160\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 154ms/step - loss: 0.0162\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 156ms/step - loss: 0.0198\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: 0.0078\n",
      "Test loss: 0.009682813659310341\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e1cc57",
   "metadata": {},
   "source": [
    "#### Experiment with different batch sizes\n",
    "- Train the model with a batch size of 16. \n",
    "\n",
    "- Train the model with a batch size of 64. \n",
    "\n",
    "- Compare the training time and performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49451519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - loss: 0.0193\n",
      "Epoch 2/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 91ms/step - loss: 0.0239\n",
      "Epoch 3/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 89ms/step - loss: 0.0272\n",
      "Epoch 4/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - loss: 0.0248\n",
      "Epoch 5/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - loss: 0.0256\n",
      "Epoch 6/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - loss: 0.0381\n",
      "Epoch 7/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - loss: 0.0193\n",
      "Epoch 8/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - loss: 0.0170\n",
      "Epoch 9/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - loss: 0.0170\n",
      "Epoch 10/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 80ms/step - loss: 0.0234\n",
      "Epoch 11/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - loss: 0.0119\n",
      "Epoch 12/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - loss: 0.0227\n",
      "Epoch 13/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 85ms/step - loss: 0.0266\n",
      "Epoch 14/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 88ms/step - loss: 0.0166\n",
      "Epoch 15/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - loss: 0.0123\n",
      "Epoch 16/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 97ms/step - loss: 0.0103\n",
      "Epoch 17/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - loss: 0.0198\n",
      "Epoch 18/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - loss: 0.0124\n",
      "Epoch 19/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - loss: 0.0113\n",
      "Epoch 20/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 84ms/step - loss: 0.0173\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.0018\n",
      "Test loss with batch size 16: 0.0014676391147077084\n",
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 264ms/step - loss: 0.0082\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 268ms/step - loss: 0.0057\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 264ms/step - loss: 0.0042\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 267ms/step - loss: 0.0040\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 270ms/step - loss: 0.0034\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 268ms/step - loss: 0.0035\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 269ms/step - loss: 0.0033\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 266ms/step - loss: 0.0040\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 265ms/step - loss: 0.0033\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 270ms/step - loss: 0.0032\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 267ms/step - loss: 0.0033\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 266ms/step - loss: 0.0040\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 268ms/step - loss: 0.0048\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 265ms/step - loss: 0.0040\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 283ms/step - loss: 0.0033\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 286ms/step - loss: 0.0040\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 269ms/step - loss: 0.0035\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 288ms/step - loss: 0.0041\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 269ms/step - loss: 0.0028\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 282ms/step - loss: 0.0032\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - loss: 0.0022\n",
      "Test loss with batch size 64: 0.0018965721828863025\n"
     ]
    }
   ],
   "source": [
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1946bc8",
   "metadata": {},
   "source": [
    "#### Use a different activation function\n",
    "- Change the activation function of the Dense layer to `tanh`. \n",
    "\n",
    "- Train and evaluate the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "870ad660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 144ms/step - loss: 0.2120\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 144ms/step - loss: 0.0267\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 144ms/step - loss: 0.0091\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 136ms/step - loss: 0.0038\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 138ms/step - loss: 0.0027\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 146ms/step - loss: 0.0021\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 144ms/step - loss: 0.0020\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 140ms/step - loss: 0.0023\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 144ms/step - loss: 0.0027\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 142ms/step - loss: 0.0019\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 140ms/step - loss: 0.0018\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 149ms/step - loss: 0.0021\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 141ms/step - loss: 0.0022\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 140ms/step - loss: 0.0018\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 142ms/step - loss: 0.0019\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 158ms/step - loss: 0.0029\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 157ms/step - loss: 0.0028\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 151ms/step - loss: 0.0020\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 142ms/step - loss: 0.0032\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 142ms/step - loss: 0.0017\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - loss: 0.0012\n",
      "Test loss with tanh activation: 0.0008125330205075443\n"
     ]
    }
   ],
   "source": [
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
